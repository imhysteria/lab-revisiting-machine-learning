{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b3cc939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ee0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2853f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0727e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('learningSet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58764990",
   "metadata": {},
   "source": [
    "## Lesson 7.01 - Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b37b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d33a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2999bb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TARGET_B'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9076e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TARGET_D'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd61d11",
   "metadata": {},
   "source": [
    "## Lesson 7.01 - Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b37bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK FOR NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a1759",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7991ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_percent_df = pd.DataFrame(data.isna().sum()/len(data)).reset_index()\n",
    "nulls_percent_df\n",
    "nulls_percent_df.columns = ['column_name', 'nulls_percentage']\n",
    "nulls_percent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c408e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_percent_df[nulls_percent_df['nulls_percentage']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f766446",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_percent_df[nulls_percent_df['nulls_percentage']!=0].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_percent_df[nulls_percent_df['nulls_percentage']!=0].tail(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb2b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_above_threshold = nulls_percent_df[nulls_percent_df['nulls_percentage']>0.25]\n",
    "columns_above_threshold['column_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c7b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns_list = list(columns_above_threshold['column_name'])\n",
    "print(drop_columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f1153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP COLUMNS OVER 25% THRESHOLD EXCEPT WEALTH1 WEALTH2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f0df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_omit = ['WEALTH1','WEALTH2']\n",
    "drop_columns_list = [col for col in drop_columns_list if col not in columns_to_omit]\n",
    "print(drop_columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4bb936",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=drop_columns_list)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21b3762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8de1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX MAILCODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5dd9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MAILCODE'].value_counts()\n",
    "data['MAILCODE'] = data['MAILCODE'].apply(lambda x: x.replace(\" \", \"A\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b8185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE BLANKS WITH NAN VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(lambda x: x.replace(\" \", np.NaN))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a251d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPEAT DROP COLUMNS ABOVE 25% THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259edf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_percent_df2 = pd.DataFrame(data.isna().sum()/len(data)).reset_index()\n",
    "nulls_percent_df2\n",
    "nulls_percent_df2.columns = ['column_name', 'nulls_percentage']\n",
    "nulls_percent_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e4b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_percent_df2[nulls_percent_df2['nulls_percentage']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e846d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_percent_df2[nulls_percent_df2['nulls_percentage']!=0].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e68b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_percent_df[nulls_percent_df['nulls_percentage']!=0].tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f50a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_above_threshold2 = nulls_percent_df2[nulls_percent_df2['nulls_percentage']>0.25]\n",
    "columns_above_threshold2['column_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a0a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns_list2 = list(columns_above_threshold2['column_name'])\n",
    "print(drop_columns_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd9caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_omit2 = ['WEALTH1','WEALTH2', 'SOLIH','VETERANS']\n",
    "drop_columns_list2 = [col for col in drop_columns_list2 if col not in columns_to_omit2]\n",
    "print(drop_columns_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5373b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=drop_columns_list2)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df797ac",
   "metadata": {},
   "source": [
    "## Lesson 7.01 - Separate Data Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964df14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data[['TARGET_B', 'TARGET_D']]\n",
    "display(Y.head(30))\n",
    "print(Y.isna().any().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = data.select_dtypes(np.number)\n",
    "numerical = numerical.drop(columns = ['TARGET_B', 'TARGET_D'])\n",
    "\n",
    "display(numerical.head())\n",
    "display(numerical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d2b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = data.select_dtypes(object)\n",
    "display(categorical.head())\n",
    "display(categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_iqr(data, factor=1.5):\n",
    "    # Calculating the first quartile (Q1) and third quartile (Q3) for each column\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    # Calculating the IQR (Interquartile Range) for each column\n",
    "    IQR = Q3 - Q1\n",
    "    # Defining the lower and upper bounds for identifying outliers\n",
    "    lower_bound = Q1 - factor * IQR\n",
    "    upper_bound = Q3 + factor * IQR\n",
    "    # Finding outliers by comparing values to the bounds\n",
    "    outliers = ((data < lower_bound) | (data > upper_bound))\n",
    "    # Count the number of outliers in each column\n",
    "    outlier_count = outliers.sum()\n",
    "    outlier_info = pd.DataFrame({'Columns': outlier_count.index, 'Outlier Count': outlier_count.values})\n",
    "    return outliers, outlier_info\n",
    "# Set the IQR factor for outlier detection (default is 1.5)\n",
    "iqr_factor = 1.5\n",
    "# Find outliers in the continuous_df DataFrame and get outlier counts\n",
    "outliers, outlier_info = find_outliers_iqr(numerical, factor=iqr_factor)\n",
    "# Display the DataFrame of outliers (True indicates an outlier)\n",
    "print(\"Outliers:\")\n",
    "print(outliers)\n",
    "# Display the DataFrame with outlier counts\n",
    "print(\"\\nOutlier Counts:\")\n",
    "outlier_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca44a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rows = outlier_info[outlier_info['Outlier Count'] > 0]\n",
    "display(filtered_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbfee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING WITH CATEGORICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df651cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.isna().sum()/len(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac5467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK FOR UNIQUE VALUES WITHIN CATEGORICAL DF\n",
    "\n",
    "for column_name in categorical.columns:\n",
    "    column_unique_counts = categorical[column_name].value_counts()\n",
    "    print(f\"Unique counts for column '{column_name}':\\n{column_unique_counts}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d1ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(categorical['STATE'].value_counts()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(categorical['STATE'].value_counts()).reset_index()\n",
    "\n",
    "df.columns = ['state', 'count']\n",
    "other_states = list(df[df['count']<2500]['state'])\n",
    "\n",
    "def clean_state(x):\n",
    "    if x in other_states:\n",
    "        return 'other'\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "categorical['STATE'] = list(map(clean_state, categorical['STATE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe3c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical['STATE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa753357",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e98d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48e3bdf2",
   "metadata": {},
   "source": [
    "# W7 Lab 1 - Revisiting Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf59ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP CATEGORICAL VALUES > 50% THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.isna().sum()/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f844262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_percent_df3 = pd.DataFrame(categorical.isna().sum()/len(categorical)).reset_index()\n",
    "nulls_percent_df3\n",
    "nulls_percent_df3.columns = ['column_name', 'nulls_percentage']\n",
    "nulls_percent_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3262791",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_percent_df3[nulls_percent_df3['nulls_percentage']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf1fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_above_threshold3 = nulls_percent_df3[nulls_percent_df3['nulls_percentage']>0.50]\n",
    "columns_above_threshold3['column_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d61bc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN GENDER VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26164bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical['GENDER'].unique()\n",
    "categorical['GENDER'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f56fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical['GENDER'].fillna('F', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_replace = ['J','C','U','A',]\n",
    "replacement_value = 'Oth'\n",
    "categorical['GENDER'].replace(values_to_replace, replacement_value, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0191ca91",
   "metadata": {},
   "source": [
    "## Lesson 7.02 - Data Cleaning Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d55392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN DOMAIN VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical['DOMAIN'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3fa168",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical['DOMAIN'] = categorical['DOMAIN'].fillna('R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf87a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical['DOMAIN_A'] = list(map(lambda x: x[0], categorical['DOMAIN']))\n",
    "categorical['DOMAIN_B'] = list(map(lambda x: x[1], categorical['DOMAIN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.DOMAIN_A.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = categorical.drop(columns=['DOMAIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce44378",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e623e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(categorical.MAILCODE.value_counts())\n",
    "print(categorical.NOEXCH.value_counts())\n",
    "print(categorical.MDMAUD.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d2869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DROP LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3a6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = categorical[['SOLIH','VETERANS','OSOURCE','ZIP','MAILCODE','MDMAUD','NOEXCH']].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d119d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = drop_list + ['MDMAUD_R', 'MDMAUD_F','MDMAUD_A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e800c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0268a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP OTHER NAN VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e307b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical['CLUSTER'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical['CLUSTER'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(categorical['CLUSTER'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical['CLUSTER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23982a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(categorical['CLUSTER'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6c939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical['CLUSTER'] = categorical['CLUSTER'].fillna('40') # 'other' would also be a valid choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical['HOMEOWNR'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5fde0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical['HOMEOWNR'] = categorical['HOMEOWNR'].fillna('U') # assumption: NAN also means 'we don't know'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef14754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACING NAN VALUES IN DATASRCE AND GEOCODE2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1ca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical['DATASRCE'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba0bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical['DATASRCE'].fillna('1', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b6ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACING GEOCODE2 with Mode Values\n",
    "\n",
    "mode_geocode2 = categorical['GEOCODE2'].mode().iloc[0]\n",
    "categorical['GEOCODE2'].fillna(mode_geocode2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6531683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical['GEOCODE2'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c124502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE COLUMNS WITH 'ADATE_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327f898",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(df.filter(like='ADATE_').columns, axis=1)\n",
    "display(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88210458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTINUING CLEANING CATEGORICAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical['RFA_6'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd80b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in categorical.columns:\n",
    "    if 'RFA' in col_name:\n",
    "        drop_list.append(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b043e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list.remove('RFA_2R')\n",
    "drop_list.remove('RFA_2A')\n",
    "drop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = categorical.drop(columns=drop_list)\n",
    "categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df67fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04723e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['OSOURCE'].value_counts(dropna=False).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e419f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['OSOURCE'] = data['OSOURCE'].fillna('MBC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f4207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical = categorical.drop(columns=['OSOURCE', 'ZIP'])\n",
    "# categorical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ace9c24",
   "metadata": {},
   "source": [
    "## Lesson 7.02 - Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46fcd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92330bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af79997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(numerical.isna().sum()).reset_index()\n",
    "df.columns = ['column_name', 'nulls']\n",
    "df[df['nulls']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK FOR NAN VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28582f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_wealth1 = numerical['WEALTH1'].mode().iloc[0]\n",
    "numerical['WEALTH1'].fillna(mode_wealth1, inplace=True)\n",
    "\n",
    "# numerical['WEALTH1'] = numerical.WEALTH1.interpolate(method='nearest', axis=0)\n",
    "# numerical = numerical.dropna(subset=['WEALTH1'])\n",
    "\n",
    "print(numerical['WEALTH1'].value_counts(dropna=False))\n",
    "numerical['WEALTH1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d7711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_wealth2 = numerical['WEALTH2'].mode().iloc[0]\n",
    "numerical['WEALTH2'].fillna(mode_wealth2, inplace=True)\n",
    "\n",
    "# numerical['WEALTH1'] = numerical.WEALTH1.interpolate(method='nearest', axis=0)\n",
    "# numerical = numerical.dropna(subset=['WEALTH1'])\n",
    "\n",
    "print(numerical['WEALTH2'].value_counts(dropna=False))\n",
    "numerical['WEALTH2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical['WEALTH2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28ddb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical['TIMELAG'].value_counts(dropna=False)\n",
    "\n",
    "mode_timelag = numerical['TIMELAG'].mode().iloc[0]\n",
    "numerical['TIMELAG'].fillna(mode_timelag, inplace=True)\n",
    "\n",
    "print(numerical['TIMELAG'].value_counts(dropna=False))\n",
    "\n",
    "\n",
    "# numerical['TIMELAG'].unique().tolist()\n",
    "# numerical['TIMELAG'] = numerical.TIMELAG.interpolate(method='nearest', axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f91ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP ROWS > 30 (5 YEARS) AS CONSIDERD DORMANT\n",
    "\n",
    "# numerical = numerical[numerical['TIMELAG'] <= 30]\n",
    "# numerical['TIMELAG'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3375a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILLING NAN VALUES WITH PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee47e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical['AGE'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4445fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(numerical['AGE'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4489974",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical['AGE'] = numerical[\"AGE\"].fillna(np.mean(numerical['AGE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(numerical['AGE'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523d8fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(numerical['INCOME']) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01337b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numerical['INCOME'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2556dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical['INCOME'] = numerical['INCOME'].fillna(5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64486cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(numerical[numerical['CLUSTER2'].isna()==False]['CLUSTER2']) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b5b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical['CLUSTER2'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe958ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(numerical['CLUSTER2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38225a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical['CLUSTER2'] = numerical['CLUSTER2'].fillna(np.ceil(np.mean(numerical['CLUSTER2'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde1d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ceil(np.mean(numerical['CLUSTER2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(numerical['CLUSTER2']) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a03fd9",
   "metadata": {},
   "source": [
    "# W7 Lab 2 - Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bf1f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN NUMERICAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff38d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical.isna().sum()/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7771b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY THE SAME NAN PERCENTAGE CHECK\n",
    "\n",
    "nulls_percent_df4 = pd.DataFrame(numerical.isna().sum()/len(numerical)).reset_index()\n",
    "nulls_percent_df4\n",
    "nulls_percent_df4.columns = ['column_name', 'nulls_percentage']\n",
    "nulls_percent_df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883dcb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_percent_df4[nulls_percent_df4['nulls_percentage']!=0].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01757d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numerical['MSA'].value_counts(dropna=False))\n",
    "numerical['MSA'] = numerical[\"MSA\"].fillna(np.mean(numerical['MSA']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8e3a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numerical['MSA'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numerical['ADI'].value_counts(dropna=False))\n",
    "numerical['ADI'] = numerical[\"ADI\"].fillna(np.mean(numerical['ADI']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecf0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numerical['ADI'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82acc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE NAN WITH MODE\n",
    "\n",
    "print(numerical['DMA'].value_counts(dropna=False))\n",
    "\n",
    "mode_dma = numerical['DMA'].mode()[0]\n",
    "numerical['DMA'] = numerical['DMA'].fillna(mode_dma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2dc6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERPOLATE ADATE COLUMNS AND DISTRIBUTE WITH NEAREST VALUE\n",
    "\n",
    "adate_columns = [col for col in numerical.columns if col.startswith(\"ADATE_\")]\n",
    "numerical[adate_columns] = numerical[adate_columns].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe857cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numerical['NEXTDATE'].value_counts(dropna=False))\n",
    "numerical['NEXTDATE'] = numerical.NEXTDATE.interpolate(method='nearest', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c9b1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numerical.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae39b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK ADATE_14 AND ADATE_18 COLUMNS\n",
    "\n",
    "print(numerical['ADATE_14'].value_counts(dropna=False))\n",
    "print(numerical['ADATE_18'].value_counts(dropna=False))\n",
    "\n",
    "numerical = numerical.dropna(subset=['ADATE_14'])\n",
    "numerical = numerical.dropna(subset=['ADATE_18'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eef972",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numerical.shape)\n",
    "print(categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf44417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK TO SEE IF ANY NAN VALUES\n",
    "\n",
    "print(numerical.isna().any().any())\n",
    "print(categorical.isna().any().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1464269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE TO CSV\n",
    "\n",
    "numerical.to_csv('numerical.csv', index=False)\n",
    "categorical.to_csv('categorical.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d0dc97",
   "metadata": {},
   "source": [
    "# W7 Lab 4 - Handling Data Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.concat([numerical, categorical], axis=1)\n",
    "clean_df.head(60)\n",
    "numerical.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f23dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c53022",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_b = data['TARGET_B']\n",
    "target_d = data['TARGET_D']\n",
    "donor_df = pd.concat([target_b, target_d, clean_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e00c2cd",
   "metadata": {},
   "source": [
    "## Split, Scale & Encode (V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4571a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DATAFRAME X-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15068181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the new DF as the X axis with the 'Target-B' column from the original dataframe.                                                                                    \n",
    "\n",
    "X = donor_df\n",
    "y = donor_df['TARGET_B']\n",
    "\n",
    "\n",
    "print(data['TARGET_B'].shape)\n",
    "print(clean_df.shape)\n",
    "print(clean_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7211f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seprate the training and testing data between numerical and categorical columns\n",
    "\n",
    "X_train_cat = X_train.select_dtypes(object)\n",
    "X_train_num = X_train.select_dtypes(np.number)\n",
    "\n",
    "X_test_cat = X_test.select_dtypes(object)\n",
    "X_test_num = X_test.select_dtypes(np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3412a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data using Standard Scaler\n",
    "\n",
    "transformer = StandardScaler().fit(X_train_num)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(transformer.transform(X_train_num), columns=X_train_num.columns)\n",
    "X_test_scaled = pd.DataFrame(transformer.transform(X_test_num), columns=X_test_num.columns)\n",
    "\n",
    "display(X_train_scaled.head())\n",
    "display(X_test_scaled.head())\n",
    "\n",
    "display(X_train.shape)\n",
    "display(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Categorical and drop 'CLUSTER' from OneHot Encoding due to length of unique values\n",
    "\n",
    "X_train_cat_onehot = X_train_cat.drop(columns=['CLUSTER']) \n",
    "display(X_train_cat_onehot.head())\n",
    "display(X_train_cat_onehot.shape)\n",
    "\n",
    "X_test_cat_onehot = X_test_cat.drop(columns=['CLUSTER']) \n",
    "display(X_test_cat_onehot.head())\n",
    "display(X_test_cat_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a184597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot encode the training categorical values\n",
    "\n",
    "# Fit on the training data\n",
    "encoder = OneHotEncoder(drop=\"first\", sparse=False)\n",
    "encoded_train = encoder.fit_transform(X_train_cat_onehot)\n",
    "X_train_cat_onehot_encoded = pd.DataFrame(encoded_train, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Transform the testing data using the same encoder and feature names\n",
    "encoded_test = encoder.transform(X_test_cat_onehot)\n",
    "X_test_cat_onehot_encoded = pd.DataFrame(encoded_test, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Reset index\n",
    "X_train_cat_onehot_encoded.reset_index(drop=True, inplace=True)\n",
    "X_test_cat_onehot_encoded.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the head of the encoded DataFrames\n",
    "display(X_train_cat_onehot_encoded.head())\n",
    "display(X_test_cat_onehot_encoded.head())\n",
    "\n",
    "\n",
    "# encoder = OneHotEncoder(drop=\"first\").fit(X_train_cat_onehot)\n",
    "\n",
    "# encoded_train = encoder.transform(X_train_cat_onehot).toarray()\n",
    "# X_train_cat_onehot = pd.DataFrame(encoded_train, columns = encoder.get_feature_names_out())\n",
    "\n",
    "\n",
    "# encoded_test = encoder.transform(X_test_cat_onehot).toarray()\n",
    "# X_test_cat_onehot = pd.DataFrame(encoded_test, columns = encoder.get_feature_names_out())\n",
    "\n",
    "# X_train_cat_onehot.head()\n",
    "# X_test_cat_onehot.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# encoder = OneHotEncoder(drop=\"first\", sparse=False)\n",
    "# encoded_train = encoder.fit_transform(X_train_cat_onehot)\n",
    "\n",
    "# # Get the feature names for the encoded columns\n",
    "# feature_names = encoder.get_feature_names_out()\n",
    "\n",
    "# # Display the feature names\n",
    "# print(feature_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ba8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encode the CLUSTER column due to unique value lengths\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_encoder.fit(X_train_cat[['CLUSTER']])\n",
    "\n",
    "X_train_cat['CLUSTER'] = ordinal_encoder.transform(X_train_cat[['CLUSTER']])\n",
    "X_test_cat['CLUSTER'] = ordinal_encoder.transform(X_test_cat[['CLUSTER']])\n",
    "\n",
    "X_train_cat_ord = X_train_cat[['CLUSTER']]\n",
    "X_test_cat_ord = X_test_cat[['CLUSTER']]\n",
    "\n",
    "display(X_train_cat_ord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d9b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check X dimensions and shape to ensure no data anamolies\n",
    "\n",
    "# Training Data\n",
    "display(X_train_cat_onehot_encoded.shape)\n",
    "display(X_train_cat_ord.shape)\n",
    "display(X_train_num.shape)\n",
    "\n",
    "\n",
    "# Testing Data\n",
    "display(X_train_cat_onehot_encoded.shape)\n",
    "display(X_test_cat_ord.shape)\n",
    "display(X_test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07304c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index for training and testing data\n",
    "\n",
    "X_train_cat_onehot_encoded.reset_index(drop=True, inplace=True)\n",
    "X_train_cat_ord.reset_index(drop=True, inplace=True)\n",
    "X_train_num.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_test_cat_onehot_encoded.reset_index(drop=True, inplace=True)\n",
    "X_test_cat_ord.reset_index(drop=True, inplace=True)\n",
    "X_test_num.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concact the training and testing dataframes\n",
    "\n",
    "X_train_processed = pd.concat([X_train_cat_onehot_encoded, X_train_cat_ord, X_train_num], axis=1)\n",
    "X_test_processed = pd.concat([X_test_cat_onehot_encoded, X_test_cat_ord, X_test_num], axis=1)\n",
    "\n",
    "display(X_train_processed.dtypes)\n",
    "display(X_test_processed.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f63572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFICATION MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab78eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f8f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and evaluation (Random Forest Classifier)\n",
    "\n",
    "rf_classifier1 = RandomForestClassifier(random_state=42)\n",
    "rf_classifier1.fit(X_train_processed, y_train)\n",
    "\n",
    "y_pred_rf_train1 = rf_classifier1.predict(X_train_processed)\n",
    "accuracy_rf_train1 = accuracy_score(y_train, y_pred_rf_train1)\n",
    "\n",
    "y_pred_rf_test1 = rf_classifier1.predict(X_test_processed)\n",
    "accuracy_rf_test1 = accuracy_score(y_test, y_pred_rf_test1)\n",
    "\n",
    "print(f\"RandomForestClassifier with SMOTE:\")\n",
    "print(f\"Training Accuracy -> {accuracy_rf_train1:.4f}\")\n",
    "print(f\"Test Accuracy -> {accuracy_rf_test1:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Model training and evaluation (Logistic Regression)\n",
    "\n",
    "logistic_regression1 = LogisticRegression(random_state=42)\n",
    "logistic_regression1.fit(X_train_processed, y_train)\n",
    "\n",
    "y_pred_lr_train1 = logistic_regression1.predict(X_train_processed)\n",
    "accuracy_lr_train1 = accuracy_score(y_train, y_pred_lr_train1)\n",
    "\n",
    "y_pred_lr_test1 = logistic_regression1.predict(X_test_processed)\n",
    "accuracy_lr_test1 = accuracy_score(y_test, y_pred_lr_test1)\n",
    "                                  \n",
    "print(f\"LogisticRegression with SMOTE:\")\n",
    "print(f\"Training Accuracy -> {accuracy_lr_train1:.4f}\")\n",
    "print(f\"Test Accuracy -> {accuracy_lr_test1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test1 = rf_classifier1.predict(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7410d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFICATION REPORT 1\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test1))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test1))\n",
    "\n",
    "# Display some of the predicted and actual values\n",
    "results_df1 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_test1})\n",
    "print(\"\\nActual vs Predicted:\")\n",
    "print(results_df1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfdd397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_true and y_pred are your true and predicted labels\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_test1, average='binary')\n",
    "\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1 Score: {f1:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d6a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [RandomForestClassifier(random_state=42), LogisticRegression()]\n",
    "# models_automation(models, X_train_processed, y_train, X_test_processed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8115d60",
   "metadata": {},
   "source": [
    "### First Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040a4fbd",
   "metadata": {},
   "source": [
    "Despite the data set being quite unbalanced, I seem to have a high RFC and LR score. This is without dropping any feature columns, but rather just encoding/scaling. I can summarise, unless there was a mistake in the encoding that with the amount of information, we can assume that we are able to predict 'TARGET_B'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a4124",
   "metadata": {},
   "source": [
    "# Restart Data PreProcessing (V2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb056672",
   "metadata": {},
   "source": [
    "Based on the existing DF without upsampling, we can see that the model isn't optimal. With this information I want to re-process the data, re-encode and upsample before splitting for train/testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e086961",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_df\n",
    "y = data['TARGET_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c17169",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X.shape)\n",
    "display(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e779669",
   "metadata": {},
   "source": [
    "## Scale & Encode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2840ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEPARATE NUM & CAT FOR SCALE & ENCODING\n",
    "\n",
    "X_cat = X.select_dtypes(object)\n",
    "X_num = X.select_dtypes(np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f2add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALE NUMERICAL\n",
    "\n",
    "transformer = StandardScaler().fit(X_num)\n",
    "X_num_scaled = pd.DataFrame(transformer.transform(X_num), columns=X_num.columns)\n",
    "\n",
    "display(X_num_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06daa64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Categorical and drop 'CLUSTER' from OneHot Encoding due to length of unique values\n",
    "\n",
    "X_cat_onehot = X_cat.drop(columns=['CLUSTER']) \n",
    "display(X_cat_onehot.head())\n",
    "display(X_cat_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8ef502",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_cat_onehot.isnull().sum())\n",
    "print(X_cat_onehot.dtypes)\n",
    "print(encoder.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b70a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONEHOT ENCODE CATEGORICAL DATA\n",
    "\n",
    "encoder = OneHotEncoder(drop=\"first\", sparse=False)\n",
    "encoded = encoder.fit_transform(X_cat_onehot)\n",
    "X_cat_encoded = pd.DataFrame(encoded, columns=encoder.get_feature_names_out())\n",
    "\n",
    "display(X_cat_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f098c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORDINAL ENCODE THE CLUSTER COLUMN\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_encoder.fit(X_cat[['CLUSTER']])\n",
    "\n",
    "X_cat['CLUSTER'] = ordinal_encoder.transform(X_cat[['CLUSTER']])\n",
    "\n",
    "X_cat_ord = X_cat[['CLUSTER']]\n",
    "\n",
    "display(X_cat_ord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d838e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index for training and testing data\n",
    "\n",
    "X_num_scaled.reset_index(drop=True, inplace=True)\n",
    "X_cat_ord.reset_index(drop=True, inplace=True)\n",
    "X_cat_encoded.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concact the training and testing dataframes\n",
    "\n",
    "X_processed = pd.concat([X_num_scaled, X_cat_ord, X_cat_encoded], axis=1)\n",
    "\n",
    "display(X_processed.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59368983",
   "metadata": {},
   "source": [
    "## Upsampling Data (V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297c43f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DATA BEFORE UPSAMPLING\n",
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_processed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a7f0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCAT PROCESSED DATA FOR UPSAMPLING\n",
    "\n",
    "processed_df = pd.concat([X_train_2, y_train_2], axis=1)\n",
    "\n",
    "df_majority = processed_df[processed_df['TARGET_B'] == 0]\n",
    "df_minority = processed_df[processed_df['TARGET_B'] == 1]\n",
    "\n",
    "# Upsample the training data\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "X_train_upsampled = df_upsampled.drop('TARGET_B', axis=1)\n",
    "y_train_upsampled = df_upsampled['TARGET_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a2cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train_upsampled)\n",
    "display(y_train_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0515e35c",
   "metadata": {},
   "source": [
    "## Re-test Classifcation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c3f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and evaluation (Random Forest Classifier)\n",
    "\n",
    "rf_classifier2 = RandomForestClassifier(random_state=42)\n",
    "rf_classifier2.fit(X_train_upsampled, y_train_upsampled)\n",
    "\n",
    "y_pred_rf_train2 = rf_classifier2.predict(X_train_upsampled)\n",
    "accuracy_rf_train2 = accuracy_score(y_train_upsampled, y_pred_rf_train2)\n",
    "\n",
    "y_pred_rf_test2 = rf_classifier2.predict(X_test_2)\n",
    "accuracy_rf_test2 = accuracy_score(y_test_2, y_pred_rf_test2)\n",
    "\n",
    "print(f\"RandomForestClassifier with Resample:\")\n",
    "print(f\"Training Accuracy -> {accuracy_rf_train2:.4f}\")\n",
    "print(f\"Test Accuracy -> {accuracy_rf_test2:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Model training and evaluation (Logistic Regression)\n",
    "\n",
    "logistic_regression2 = LogisticRegression(random_state=42)\n",
    "logistic_regression2.fit(X_train_upsampled, y_train_upsampled)\n",
    "\n",
    "y_pred_lr_train2 = logistic_regression2.predict(X_train_upsampled)\n",
    "accuracy_lr_train2 = accuracy_score(y_train_upsampled, y_pred_lr_train2)\n",
    "\n",
    "y_pred_lr_test2 = logistic_regression2.predict(X_test_2)\n",
    "accuracy_lr_test2 = accuracy_score(y_test_2, y_pred_lr_test2)\n",
    "                                  \n",
    "print(f\"LogisticRegression with Resample:\")\n",
    "print(f\"Training Accuracy -> {accuracy_lr_train2:.4f}\")\n",
    "print(f\"Test Accuracy -> {accuracy_lr_test2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47005a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test2 = rf_classifier2.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c6fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFICATION REPORT 2\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_2, y_pred_test2))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_2, y_pred_test2))\n",
    "\n",
    "# Display some of the predicted and actual values\n",
    "results_df2 = pd.DataFrame({'Actual': y_test_2, 'Predicted': y_pred_test2})\n",
    "print(\"\\nActual vs Predicted:\")\n",
    "print(results_df2.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRECISION RECALL F1 COMPARISON\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test_2, y_pred_test2, average='binary')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988f067d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1759fccd",
   "metadata": {},
   "source": [
    "### Second Concluson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe57239",
   "metadata": {},
   "source": [
    "The first obversation is that the RFC scores have improved to almost perfect on both training and testing data. This implies that the upsampled data has improved performance on both counts. For the LR, it has decreased dramatically which could suggest that it's struggling to fit with the upsampled data.\n",
    "\n",
    "The next step i'd like to try is to upsample the data using another method, in this case SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc28c58a",
   "metadata": {},
   "source": [
    "## Resample using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d9aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the processed data prior to the upsample\n",
    "\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_processed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d73bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE only to the training data\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_3, y_train_3)\n",
    "\n",
    "\n",
    "# Model training and evaluation (Random Forest Classifier)\n",
    "\n",
    "rf_classifier3 = RandomForestClassifier(random_state=42)\n",
    "rf_classifier3.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred_rf_train3 = rf_classifier3.predict(X_train_smote)\n",
    "accuracy_rf_train3 = accuracy_score(y_train_smote, y_pred_rf_train3)\n",
    "\n",
    "y_pred_rf_test3 = rf_classifier3.predict(X_test_3)\n",
    "accuracy_rf_test3 = accuracy_score(y_test_3, y_pred_rf_test3)\n",
    "\n",
    "print(f\"RandomForestClassifier with SMOTE:\")\n",
    "print(f\"Training Accuracy -> {accuracy_rf_train3:.4f}\")\n",
    "print(f\"Test Accuracy -> {accuracy_rf_test3:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Model training and evaluation (Logistic Regression)\n",
    "\n",
    "logistic_regression3 = LogisticRegression(random_state=42)\n",
    "logistic_regression3.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred_lr_train3 = logistic_regression3.predict(X_train_smote)\n",
    "accuracy_lr_train3 = accuracy_score(y_train_smote, y_pred_lr_train3)\n",
    "\n",
    "y_pred_lr_test3 = logistic_regression3.predict(X_test_3)\n",
    "accuracy_lr_test3 = accuracy_score(y_test_3, y_pred_lr_test3)\n",
    "                                  \n",
    "print(f\"LogisticRegression with SMOTE:\")\n",
    "print(f\"Training Accuracy -> {accuracy_lr_train3:.4f}\")\n",
    "print(f\"Test Accuracy -> {accuracy_lr_test3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efcfe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test3 = rf_classifier3.predict(X_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c1cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSFICATION REPORT 3\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_3, y_pred_test3))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_3, y_pred_test3))\n",
    "\n",
    "# Display some of the predicted values and actual values\n",
    "results_df3 = pd.DataFrame({'Actual': y_test_3, 'Predicted': y_pred_test3})\n",
    "print(\"\\nActual vs Predicted:\")\n",
    "print(results_df3.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3945885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRECISION RECALL F1 COMPARISON\n",
    "\n",
    "precision3, recall3, f13, _ = precision_recall_fscore_support(y_test_3, y_pred_test3, average='binary')\n",
    "\n",
    "print(f\"Precision: {precision3:.4f}\")\n",
    "print(f\"Recall: {recall3:.4f}\")\n",
    "print(f\"F1 Score: {f13:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72152a38",
   "metadata": {},
   "source": [
    "# W7 - Lab 5 Random Forest (V4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this part of the process, we do an RFE (Recursive Feature Elimination)\n",
    "# This is to understand if droping features has an impact on the model and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22fdd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I use the processed X-dataframes from earlier (encoded and scaled)\n",
    "\n",
    "X = pd.concat([X_train_processed, X_test_processed], axis=0)\n",
    "y = data['TARGET_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b6d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52fe22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST SPLIT\n",
    "\n",
    "X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(x_processed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e3e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# # Assuming X and y are your original features and target variable\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Upsample only the training data using SMOTE\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# # Perform RFC feature selection\n",
    "# rf_classifier = RandomForestClassifier(random_state=42)\n",
    "# rf_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# # Use feature importances for feature selection\n",
    "# sfm = SelectFromModel(rf_classifier, threshold='median')\n",
    "# sfm.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# # Transform the data to include only selected features\n",
    "# X_train_selected = sfm.transform(X_train_resampled)\n",
    "# X_test_selected = sfm.transform(X_test)\n",
    "\n",
    "# # Train RFC on the selected features\n",
    "# rf_classifier_selected = RandomForestClassifier(random_state=42)\n",
    "# rf_classifier_selected.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = rf_classifier_selected.predict(X_test_selected)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e30e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train_resampled)\n",
    "display(y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374195c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "ratio_class_0_to_1 = 90000 / 4000\n",
    "class_weights = {0: 1.0, 1: ratio_class_0_to_1}\n",
    "# class_weights = {0: 1.0, 1: 50.0} \n",
    "\n",
    "\n",
    "rf_classifier4 = RandomForestClassifier(n_estimators=500, class_weight=class_weights, random_state=42)\n",
    "rf_classifier4.fit(X_train_4, y_train_4)\n",
    "\n",
    "\n",
    "feature_importances = rf_classifier4.feature_importances_\n",
    "\n",
    "k = 100\n",
    "top_features_indices = feature_importances.argsort()[-k:][::-1]\n",
    "\n",
    "X_selected_train = X_train_4.iloc[:, top_features_indices]\n",
    "X_selected_test = X_test_4.iloc[:, top_features_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb75d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train Random Forest Classifier on Selected Features\n",
    "rf_classifier4.fit(X_selected_train, y_train_4)\n",
    "\n",
    "# Step 6: Make Predictions and Evaluate\n",
    "y_pred = rf_classifier4.predict(X_selected_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_4, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_4, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b62f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = pd.concat([X_selected_train, X_selected_test], axis=0)\n",
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7611eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_all is your entire DataFrame with features\n",
    "predictions_all = rf_classifier4.predict(X_all)\n",
    "X_all['Predicted_Target_B'] = predictions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bfb243",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all['Predicted_Target_B'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e512bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all.to_csv('pred_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a02758",
   "metadata": {},
   "source": [
    "# Process 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f89630",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_data = donor_df[donor_df['TARGET_B'] == 1]\n",
    "subset_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e8d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = subset_data\n",
    "y = subset_data['TARGET_D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74333c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X.shape)\n",
    "display(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3838ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat_p2 = X.select_dtypes(object)\n",
    "X_num_p2 = X.select_dtypes(np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c061f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer = StandardScaler()\n",
    "X_num_scaled = pd.DataFrame(transformer.transform(X_num_p2), columns=X_num.columns)\n",
    "\n",
    "display(X_num_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a58f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat_onehot = X_cat.drop(columns=['CLUSTER']) \n",
    "display(X_cat_onehot.head())\n",
    "display(X_cat_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d1ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subset_train, X_subset_test, y_subset_train, y_subset_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355cd5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming scaler is the scaler used in Process 1\n",
    "X_subset_train_scaled = scaler.transform(X_subset_train)\n",
    "X_subset_test_scaled = scaler.transform(X_subset_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
